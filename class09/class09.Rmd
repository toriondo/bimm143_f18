---
title: "class09"
name: "Tori Ondo"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Preparing Data

```{r}
url <- "https://bioboot.github.io/bimm143_S18/class-material/WisconsinCancer.csv"

wisc.df <- read.csv(url)

#get a matrix of column 3-32
wisc.data <- as.matrix(wisc.df[,3:32])

# Set the row names of wisc.data
row.names(wisc.data) <- wisc.df$id
#head(wisc.data) this views first couple

```

```{r}
# Create diagnosis vector by completing the missing code
diagnosis <- as.numeric(wisc.df$diagnosis=="M")

#check how many should be
table(wisc.df$diagnosis == "M")

#check diagnosis gives correct value
sum(diagnosis)
```

Q1. How many observations are in this dataset?
```{r}
nrow(wisc.df)
```

Q2. How many variables/features in the data are suffixed with _mean?
```{r}
#show which values have _mean in its name 
grep("_mean", colnames(wisc.data))

#to count how many there are
length(grep("_mean", colnames(wisc.data)))
```


Q3. How many of the observations have a malignant diagnosis?

```{r}
table(wisc.df$diagnosis == "M")
```

##PCA
```{r}
#might need to scale data so they are comparable
#check means of data
colMeans(wisc.data)

#check standard deviation
apply(wisc.data,2,sd)
```

```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp( wisc.data, scale=T )
summary(wisc.pr)
```
Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

```{r}
#find what to plot to show the cumulative proportion
attributes(wisc.pr)
#this shows its "x"

#add +1 to col because F gives a Zero value that shows up white
plot( wisc.pr$x[,1], wisc.pr$x[,2], col = diagnosis+1, 
     xlab = "PC1", ylab = "PC2")
```
```{r}
# Repeat for components 1 and 3
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1), 
     xlab = "PC1", ylab = "PC3")
```

```{r}
#Calculate the variance of each principal component by squaring the sdev component
pr.var <- wisc.pr$sdev^2

# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```
```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

```{r}
# Plot cumulative proportion of variance explained
plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```
```{r}
#to get two graphs next to each other
par(mfrow=c(1,2))
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?
  4
  

##Hierarchical clustering of case data

```{r}
# Scale the wisc.data data: data.scaled
data.scaled <- scale(wisc.data)

data.dist <- dist(data.scaled)

#Create a hierarchical clustering model using complete linkage
wisc.hclust <- hclust(data.dist, method = "complete")

hcluster <- plot(wisc.hclust)



```

to analyze this, cut it into different clusters
```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)

wisc.hclust.clusters

table(wisc.hclust.clusters, diagnosis)
```

try again with 6 clusters
```{r}
wisc.hclust.clusters6 <- cutree(wisc.hclust, k=6)

table(wisc.hclust.clusters6, diagnosis)
```
with 3
```{r}
wisc.hclust.clusters3 <- cutree(wisc.hclust, k=3)

table(wisc.hclust.clusters3, diagnosis)
```


##Clustering on PCA results

```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
# need to input distance vector
d.pr <- dist(wisc.pr$x[, 1:7])
wisc.pr.hclust <- hclust(d.pr, method="complete")
plot(wisc.pr.hclust)
```
check how well it did
```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=4)
table(wisc.pr.hclust.clusters, diagnosis)
```
this does worse at seperating the diagnoses into clusters than the hieracrchical clusters

```{r}
#to predict whether these 2 people would have cancer or not

url2 <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url2)
npc <- predict(wisc.pr, newdata=new)
plot(wisc.pr$x[,1:2], col=diagnosis+1)
points(npc[,1], npc[,2], col="blue", pch=16)
```




